---
sidebar_position: 5
---

# Ollama

Site officiel https://ollama.ai

Projet open source pour exécuter, créer et partager de grands modèles de langage (LLMs).
## Connecter les modèles Ollama
- Téléchargez Ollama depuis le lien suivant : [ollama.ai](https://ollama.ai/)
- Installez Ollama et utilisez le modèle codellama en exécutant la commande ```ollama pull codellama```
- Si vous souhaitez utiliser mistral ou d'autres modèles, vous devrez remplacer codellama par le modèle souhaité. Par exemple : ```ollama pull mistral```

# Comment utiliser Ollama
- Dans VSCode, sélectionnez Ollama comme `Fournisseur`
 
<p align="center">
      <img width="400" height="300" src="https://github.com/davila7/code-gpt-docs/assets/37567214/a5e3eda0-1609-44b4-bffb-a275ba2562b0" />
</p>
 
- Veuillez noter que Ollama s'exécute localement sur votre ordinateur.

## Modèles Ollama disponibles dans Code GPT
- llama2
- codellama
- phi
- mistral
- mixtral
- deepseek-coder

## Erreurs API
Si vous rencontrez des erreurs API, consultez le lien suivant : [Documentation de Ollama](https://ollama.ai/)

Si le modèle Ollama ne répond pas dans le chat, envisagez de le redémarrer localement en l'éteignant puis en le rallumant. Cette action devrait résoudre le problème.

<p align="center">
      <img width="250" height="00" src="https://github.com/davila7/code-gpt-docs/assets/37567214/4bd4e2c8-dbfb-46f3-b4d3-c3484cc7692c" />
</p>



